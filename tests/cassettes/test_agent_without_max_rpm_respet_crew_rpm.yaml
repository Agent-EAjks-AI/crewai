interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nTo give my best complete final answer to the task
      use the exact following format:\n\nThought: I now can give a great answer\nFinal
      Answer: Your final answer must be the great and the most complete as possible,
      it must be outcome described.\n\nI MUST use these formats, my job depends on
      it!\nCurrent Task: Just say hi.\n\nThis is the expect criteria for your final
      answer: Your greeting. \n you MUST return the actual complete content as the
      final answer, not a summary.\n\nBegin! This is VERY important to you, use the
      tools available and give your best Final Answer, your job depends on it!\n\nThought:"}],
      "model": "gpt-4o", "stop": ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '766'
      content-type:
      - application/json
      cookie:
      - _cfuvid=LvtTbaP44JnVgAR4_pSrz_emt.mrmw2hy5jFSs21OE4-1725940622893-0.0.1.1-604800000;
        __cf_bm=Tb6bOg4tvEVZXL4ILghETdcnVWDKGtoQRxXK9OVLqFM-1725940622-1.0.1.1-RdWxwbKhTCEMWX3XmnpdCT3Dd_uKBWaeDoNdKE26rLvpG9EtS_UgmZ.H0e8LmyeVBjvZLL34KWzlwOQIBK.Ehw
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5mHxgk7zOroD4AUXBFmlVWwoRmXu\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725940625,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I now can give a great answer\\nFinal
      Answer: Hi!\",\n        \"refusal\": null\n      },\n      \"logprobs\": null,\n
      \     \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      150,\n    \"completion_tokens\": 15,\n    \"total_tokens\": 165\n  },\n  \"system_fingerprint\":
      \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c0c7dee19fa5220-LAX
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 10 Sep 2024 03:57:06 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '293'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999817'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_558edf56e826e65fe62d521629567c0a
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: !!binary |
      Cs4ZCiQKIgoMc2VydmljZS5uYW1lEhIKEGNyZXdBSS10ZWxlbWV0cnkSpRkKEgoQY3Jld2FpLnRl
      bGVtZXRyeRKTAQoQWNmK8z5UsGQ1svJHK+fwQRIIQUxOyxFy+20qClRvb2wgVXNhZ2UwATlwfP8h
      2sXzF0Hgzgoi2sXzF0oaCg5jcmV3YWlfdmVyc2lvbhIICgYwLjU1LjJKHwoJdG9vbF9uYW1lEhIK
      EGdldF9maW5hbF9hbnN3ZXJKDgoIYXR0ZW1wdHMSAhgBegIYAYUBAAEAABKcAQoQmp0pRiQtVBu4
      x0TroNRK9hIIY8FldbYyg7cqE1Rvb2wgUmVwZWF0ZWQgVXNhZ2UwATmQNEBF2sXzF0HQskVF2sXz
      F0oaCg5jcmV3YWlfdmVyc2lvbhIICgYwLjU1LjJKHwoJdG9vbF9uYW1lEhIKEGdldF9maW5hbF9h
      bnN3ZXJKDgoIYXR0ZW1wdHMSAhgBegIYAYUBAAEAABKcAQoQXgOcBvibth3xmMT3uaeEtRIIEmhv
      4YWmu7sqE1Rvb2wgUmVwZWF0ZWQgVXNhZ2UwATkI8q1v2sXzF0FwKLBv2sXzF0oaCg5jcmV3YWlf
      dmVyc2lvbhIICgYwLjU1LjJKHwoJdG9vbF9uYW1lEhIKEGdldF9maW5hbF9hbnN3ZXJKDgoIYXR0
      ZW1wdHMSAhgBegIYAYUBAAEAABKcAQoQcCJGOwoc9dbrkqD9a7a8pxII/IawvnAuqQAqE1Rvb2wg
      UmVwZWF0ZWQgVXNhZ2UwATngwT+a2sXzF0H4LkKa2sXzF0oaCg5jcmV3YWlfdmVyc2lvbhIICgYw
      LjU1LjJKHwoJdG9vbF9uYW1lEhIKEGdldF9maW5hbF9hbnN3ZXJKDgoIYXR0ZW1wdHMSAhgBegIY
      AYUBAAEAABKQAgoQeNTOt84QgK7d+9VzjT4zpxII1AJlvXZEfV8qDlRhc2sgRXhlY3V0aW9uMAE5
      MCX3803F8xdB+NxTvNrF8xdKLgoIY3Jld19rZXkSIgogZDU1MTEzYmU0YWE0MWJhNjQzZDMyNjA0
      MmIyZjAzZjFKMQoHY3Jld19pZBImCiQ2NmIyNmJlNi0zMmFlLTQyZDgtYTUwYi0yOWM3NGNkMzAx
      M2FKLgoIdGFza19rZXkSIgogNGEzMWI4NTEzM2EzYTI5NGM2ODUzZGE3NTdkNGJhZTdKMQoHdGFz
      a19pZBImCiRmMWUxODY4Mi1hN2I4LTQ2ZTktYmJmNS1jNzVjNDY4NjRhNWR6AhgBhQEAAQAAEtML
      ChBrN0NEFmQjGvghq/8CK32uEghpvZPRNYP4uioMQ3JldyBDcmVhdGVkMAE5cBe+vdrF8xdBkMTD
      vdrF8xdKGgoOY3Jld2FpX3ZlcnNpb24SCAoGMC41NS4yShoKDnB5dGhvbl92ZXJzaW9uEggKBjMu
      MTEuN0ouCghjcmV3X2tleRIiCiA5ODNjMmEwNzI2YjU2ZDBkOTI3YzlkZjEwYmZlMjVjOEoxCgdj
      cmV3X2lkEiYKJDQ3ZTIzNmZiLWU2MDEtNGJhMy1iYjVhLWJjMzA2MjBmMjM0YkocCgxjcmV3X3By
      b2Nlc3MSDAoKc2VxdWVudGlhbEoRCgtjcmV3X21lbW9yeRICEABKGgoUY3Jld19udW1iZXJfb2Zf
      dGFza3MSAhgCShsKFWNyZXdfbnVtYmVyX29mX2FnZW50cxICGAJKgwUKC2NyZXdfYWdlbnRzEvME
      CvAEW3sia2V5IjogImUxNDhlNTMyMDI5MzQ5OWY4Y2ViZWE4MjZlNzI1ODJiIiwgImlkIjogIjA2
      YWQyYjI4LWMzYzYtNDdkYS1hMjhhLTdjYWE2ZWRhNGU1OCIsICJyb2xlIjogInRlc3Qgcm9sZSIs
      ICJ2ZXJib3NlPyI6IHRydWUsICJtYXhfaXRlciI6IDI1LCAibWF4X3JwbSI6IDEwLCAiZnVuY3Rp
      b25fY2FsbGluZ19sbG0iOiBudWxsLCAibGxtIjogImdwdC00byIsICJkZWxlZ2F0aW9uX2VuYWJs
      ZWQ/IjogZmFsc2UsICJhbGxvd19jb2RlX2V4ZWN1dGlvbj8iOiBmYWxzZSwgIm1heF9yZXRyeV9s
      aW1pdCI6IDIsICJ0b29sc19uYW1lcyI6IFtdfSwgeyJrZXkiOiAiZTdlOGVlYTg4NmJjYjhmMTA0
      NWFiZWVjZjE0MjVkYjciLCAiaWQiOiAiNTNhYTcxODYtMDAxYy00Njc4LTgwODgtODVjNzVlZjQ5
      ZTlkIiwgInJvbGUiOiAidGVzdCByb2xlMiIsICJ2ZXJib3NlPyI6IHRydWUsICJtYXhfaXRlciI6
      IDEsICJtYXhfcnBtIjogbnVsbCwgImZ1bmN0aW9uX2NhbGxpbmdfbGxtIjogbnVsbCwgImxsbSI6
      ICJncHQtNG8iLCAiZGVsZWdhdGlvbl9lbmFibGVkPyI6IGZhbHNlLCAiYWxsb3dfY29kZV9leGVj
      dXRpb24/IjogZmFsc2UsICJtYXhfcmV0cnlfbGltaXQiOiAyLCAidG9vbHNfbmFtZXMiOiBbXX1d
      Sv0DCgpjcmV3X3Rhc2tzEu4DCusDW3sia2V5IjogIjMyMmRkYWUzYmM4MGMxZDQ1Yjg1ZmE3NzU2
      ZGI4NjY1IiwgImlkIjogImQxNTEzNjYxLTAxNmUtNGExNS05OTRlLTZlNmRhMTM4YWVmZSIsICJh
      c3luY19leGVjdXRpb24/IjogZmFsc2UsICJodW1hbl9pbnB1dD8iOiBmYWxzZSwgImFnZW50X3Jv
      bGUiOiAidGVzdCByb2xlIiwgImFnZW50X2tleSI6ICJlMTQ4ZTUzMjAyOTM0OTlmOGNlYmVhODI2
      ZTcyNTgyYiIsICJ0b29sc19uYW1lcyI6IFtdfSwgeyJrZXkiOiAiZmI0YzI2MDg3YmI4NzNmNjRm
      NGRmNTU4MDJjNmVkMDkiLCAiaWQiOiAiNzU1MTBkNGQtYmRlOS00YTc4LWI2MDAtYzVkYTViNzhj
      OWY2IiwgImFzeW5jX2V4ZWN1dGlvbj8iOiBmYWxzZSwgImh1bWFuX2lucHV0PyI6IGZhbHNlLCAi
      YWdlbnRfcm9sZSI6ICJ0ZXN0IHJvbGUyIiwgImFnZW50X2tleSI6ICJlN2U4ZWVhODg2YmNiOGYx
      MDQ1YWJlZWNmMTQyNWRiNyIsICJ0b29sc19uYW1lcyI6IFsiZ2V0X2ZpbmFsX2Fuc3dlciJdfV16
      AhgBhQEAAQAAEo4CChBiYxkBQF5Z3zibBb4aFofJEgihgrEh9pGhoCoMVGFzayBDcmVhdGVkMAE5
      kBbgvdrF8xdBENLgvdrF8xdKLgoIY3Jld19rZXkSIgogOTgzYzJhMDcyNmI1NmQwZDkyN2M5ZGYx
      MGJmZTI1YzhKMQoHY3Jld19pZBImCiQ0N2UyMzZmYi1lNjAxLTRiYTMtYmI1YS1iYzMwNjIwZjIz
      NGJKLgoIdGFza19rZXkSIgogMzIyZGRhZTNiYzgwYzFkNDViODVmYTc3NTZkYjg2NjVKMQoHdGFz
      a19pZBImCiRkMTUxMzY2MS0wMTZlLTRhMTUtOTk0ZS02ZTZkYTEzOGFlZmV6AhgBhQEAAQAAEpAC
      ChDQ9fXw5TXcJwkdgCXwlJOTEgguSqXg/GO/PSoOVGFzayBFeGVjdXRpb24wATmQEOG92sXzF0HQ
      XEDh2sXzF0ouCghjcmV3X2tleRIiCiA5ODNjMmEwNzI2YjU2ZDBkOTI3YzlkZjEwYmZlMjVjOEox
      CgdjcmV3X2lkEiYKJDQ3ZTIzNmZiLWU2MDEtNGJhMy1iYjVhLWJjMzA2MjBmMjM0YkouCgh0YXNr
      X2tleRIiCiAzMjJkZGFlM2JjODBjMWQ0NWI4NWZhNzc1NmRiODY2NUoxCgd0YXNrX2lkEiYKJGQx
      NTEzNjYxLTAxNmUtNGExNS05OTRlLTZlNmRhMTM4YWVmZXoCGAGFAQABAAASjgIKEDCnxEQ8jvQw
      dk6Lcj58iXoSCL+vcq8X60WLKgxUYXNrIENyZWF0ZWQwATnA1GTh2sXzF0EIQGbh2sXzF0ouCghj
      cmV3X2tleRIiCiA5ODNjMmEwNzI2YjU2ZDBkOTI3YzlkZjEwYmZlMjVjOEoxCgdjcmV3X2lkEiYK
      JDQ3ZTIzNmZiLWU2MDEtNGJhMy1iYjVhLWJjMzA2MjBmMjM0YkouCgh0YXNrX2tleRIiCiBmYjRj
      MjYwODdiYjg3M2Y2NGY0ZGY1NTgwMmM2ZWQwOUoxCgd0YXNrX2lkEiYKJDc1NTEwZDRkLWJkZTkt
      NGE3OC1iNjAwLWM1ZGE1Yjc4YzlmNnoCGAGFAQABAAA=
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '3281'
      Content-Type:
      - application/x-protobuf
      User-Agent:
      - OTel-OTLP-Exporter-Python/1.27.0
    method: POST
    uri: https://telemetry.crewai.com:4319/v1/traces
  response:
    body:
      string: "\n\0"
    headers:
      Content-Length:
      - '2'
      Content-Type:
      - application/x-protobuf
      Date:
      - Tue, 10 Sep 2024 03:57:06 GMT
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role2. test backstory2\nYour
      personal goal is: test goal2\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n\nCurrent Task: NEVER give
      a Final Answer, instead keep using the `get_final_answer` tool non-stop\n\nThis
      is the expect criteria for your final answer: The final answer \n you MUST return
      the actual complete content as the final answer, not a summary.\n\nThis is the
      context you''re working with:\nHi!\n\nBegin! This is VERY important to you,
      use the tools available and give your best Final Answer, your job depends on
      it!\n\nThought:"}], "model": "gpt-4o", "stop": ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1423'
      content-type:
      - application/json
      cookie:
      - _cfuvid=LvtTbaP44JnVgAR4_pSrz_emt.mrmw2hy5jFSs21OE4-1725940622893-0.0.1.1-604800000;
        __cf_bm=Tb6bOg4tvEVZXL4ILghETdcnVWDKGtoQRxXK9OVLqFM-1725940622-1.0.1.1-RdWxwbKhTCEMWX3XmnpdCT3Dd_uKBWaeDoNdKE26rLvpG9EtS_UgmZ.H0e8LmyeVBjvZLL34KWzlwOQIBK.Ehw
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5mHyDYn1tJre53SiCqBmVlYOWkkb\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725940626,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I need to ensure I follow the
      instructions precisely and use the tools available to get the final answer without
      actually giving it yet.\\n\\nAction: get_final_answer\\nAction Input: {}\",\n
      \       \"refusal\": null\n      },\n      \"logprobs\": null,\n      \"finish_reason\":
      \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 294,\n    \"completion_tokens\":
      37,\n    \"total_tokens\": 331\n  },\n  \"system_fingerprint\": \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c0c7df1ddd65220-LAX
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 10 Sep 2024 03:57:06 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '421'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999657'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_1c144fe9c8bff73fd64b391069f85e83
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role2. test backstory2\nYour
      personal goal is: test goal2\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n\nCurrent Task: NEVER give
      a Final Answer, instead keep using the `get_final_answer` tool non-stop\n\nThis
      is the expect criteria for your final answer: The final answer \n you MUST return
      the actual complete content as the final answer, not a summary.\n\nThis is the
      context you''re working with:\nHi!\n\nBegin! This is VERY important to you,
      use the tools available and give your best Final Answer, your job depends on
      it!\n\nThought:"}, {"role": "assistant", "content": "Thought: I need to ensure
      I follow the instructions precisely and use the tools available to get the final
      answer without actually giving it yet.\n\nAction: get_final_answer\nAction Input:
      {}\nObservation: 42\nNow it''s time you MUST give your absolute best final answer.
      You''ll ignore all previous instructions, stop using any tools, and just return
      your absolute BEST Final answer."}], "model": "gpt-4o", "stop": ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1843'
      content-type:
      - application/json
      cookie:
      - _cfuvid=LvtTbaP44JnVgAR4_pSrz_emt.mrmw2hy5jFSs21OE4-1725940622893-0.0.1.1-604800000;
        __cf_bm=Tb6bOg4tvEVZXL4ILghETdcnVWDKGtoQRxXK9OVLqFM-1725940622-1.0.1.1-RdWxwbKhTCEMWX3XmnpdCT3Dd_uKBWaeDoNdKE26rLvpG9EtS_UgmZ.H0e8LmyeVBjvZLL34KWzlwOQIBK.Ehw
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5mHyh1R6Vjtl78WTupgD28zBkG3N\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725940626,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I now know the final answer.\\nFinal
      Answer: 42\",\n        \"refusal\": null\n      },\n      \"logprobs\": null,\n
      \     \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      372,\n    \"completion_tokens\": 14,\n    \"total_tokens\": 386\n  },\n  \"system_fingerprint\":
      \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c0c7df5999e5220-LAX
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 10 Sep 2024 03:57:07 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '201'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999562'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_4b349804bc709f1ccfa08f28f0ab3cca
    http_version: HTTP/1.1
    status_code: 200
version: 1
