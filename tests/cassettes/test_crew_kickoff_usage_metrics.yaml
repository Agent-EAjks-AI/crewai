interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "You are dog Researcher. You
      have a lot of experience with dog.\nYour personal goal is: Express hot takes
      on dog.\nTo give my best complete final answer to the task use the exact following
      format:\n\nThought: I now can give a great answer\nFinal Answer: Your final
      answer must be the great and the most complete as possible, it must be outcome
      described.\n\nI MUST use these formats, my job depends on it!\nCurrent Task:
      Give me an analysis around dog.\n\nThis is the expect criteria for your final
      answer: 1 bullet point about dog that''s under 15 words. \n you MUST return
      the actual complete content as the final answer, not a summary.\n\nBegin! This
      is VERY important to you, use the tools available and give your best Final Answer,
      your job depends on it!\n\nThought:"}], "model": "gpt-4o", "stop": ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '863'
      content-type:
      - application/json
      cookie:
      - _cfuvid=_Qurzg7MGysLGzSugSD3ZV84qR5Lfxrt9mF2_tfTJqw-1725940709772-0.0.1.1-604800000;
        __cf_bm=_VKcRD0U2g9VfrlK3xy3AVQfynnKXZY2jX0QBkR8us8-1725940709-1.0.1.1-F0MIxvXffEPTFVqJ6cgovOMZ9E88rvBTRMj7aIlAQz.bEZJA5fip0HhCYxawoz1MDdwfQ2X_c9FjtN27PR.RHw
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5mMvXYlHhiqfbYQZvNAvAQxkTCIw\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725940933,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I now can give a great answer\\nFinal
      Answer: Dogs are more emotionally intuitive than most people give them credit
      for.\",\n        \"refusal\": null\n      },\n      \"logprobs\": null,\n      \"finish_reason\":
      \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 171,\n    \"completion_tokens\":
      26,\n    \"total_tokens\": 197\n  },\n  \"system_fingerprint\": \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c0c85703f582ae0-LAX
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 10 Sep 2024 04:02:13 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '320'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999793'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_0157b6fe8056b711f4b43e4623a7f279
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "user", "content": "You are cat Researcher. You
      have a lot of experience with cat.\nYour personal goal is: Express hot takes
      on cat.\nTo give my best complete final answer to the task use the exact following
      format:\n\nThought: I now can give a great answer\nFinal Answer: Your final
      answer must be the great and the most complete as possible, it must be outcome
      described.\n\nI MUST use these formats, my job depends on it!\nCurrent Task:
      Give me an analysis around cat.\n\nThis is the expect criteria for your final
      answer: 1 bullet point about cat that''s under 15 words. \n you MUST return
      the actual complete content as the final answer, not a summary.\n\nBegin! This
      is VERY important to you, use the tools available and give your best Final Answer,
      your job depends on it!\n\nThought:"}], "model": "gpt-4o", "stop": ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '863'
      content-type:
      - application/json
      cookie:
      - _cfuvid=_Qurzg7MGysLGzSugSD3ZV84qR5Lfxrt9mF2_tfTJqw-1725940709772-0.0.1.1-604800000;
        __cf_bm=_VKcRD0U2g9VfrlK3xy3AVQfynnKXZY2jX0QBkR8us8-1725940709-1.0.1.1-F0MIxvXffEPTFVqJ6cgovOMZ9E88rvBTRMj7aIlAQz.bEZJA5fip0HhCYxawoz1MDdwfQ2X_c9FjtN27PR.RHw
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5mMwhuo5MNHaQt1hT1qFjLkAX5L0\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725940934,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I now can give a great answer.\\nFinal
      Answer: Cats are independent yet affectionate, making them ideal companions
      for various lifestyles.\",\n        \"refusal\": null\n      },\n      \"logprobs\":
      null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      171,\n    \"completion_tokens\": 27,\n    \"total_tokens\": 198\n  },\n  \"system_fingerprint\":
      \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c0c85760f3b2ae0-LAX
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 10 Sep 2024 04:02:14 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '407'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999794'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_38bad39dd6fbbc0c7d9f1fde7cb73088
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: !!binary |
      CtYVCiQKIgoMc2VydmljZS5uYW1lEhIKEGNyZXdBSS10ZWxlbWV0cnkSrRUKEgoQY3Jld2FpLnRl
      bGVtZXRyeRKvBwoQyvIQHOheSfNhaBo90WBLPhII64Yzfb/3G/oqDENyZXcgQ3JlYXRlZDABOSjX
      N1cixvMXQcjaOVcixvMXShoKDmNyZXdhaV92ZXJzaW9uEggKBjAuNTUuMkoaCg5weXRob25fdmVy
      c2lvbhIICgYzLjExLjdKLgoIY3Jld19rZXkSIgogZWU2NzQ1ZDdjOGFlODJlMDBkZjk0ZGUwZjdm
      ODcxMThKMQoHY3Jld19pZBImCiQyOWY2NjY3ZS1iYTAwLTQ0OGYtYTMxNy05NGE1NTYyNmJjNzVK
      HAoMY3Jld19wcm9jZXNzEgwKCnNlcXVlbnRpYWxKEQoLY3Jld19tZW1vcnkSAhAAShoKFGNyZXdf
      bnVtYmVyX29mX3Rhc2tzEgIYAUobChVjcmV3X251bWJlcl9vZl9hZ2VudHMSAhgBStUCCgtjcmV3
      X2FnZW50cxLFAgrCAlt7ImtleSI6ICJmMzM4NmY2ZDhkYTc1YWE0MTZhNmUzMTAwNTNmNzY5OCIs
      ICJpZCI6ICI0Mjg3NDgwYi1iZTJmLTQzMDEtYWI3OS0zMzEzMWVkOTI2Y2YiLCAicm9sZSI6ICJ7
      dG9waWN9IFJlc2VhcmNoZXIiLCAidmVyYm9zZT8iOiBmYWxzZSwgIm1heF9pdGVyIjogMjUsICJt
      YXhfcnBtIjogbnVsbCwgImZ1bmN0aW9uX2NhbGxpbmdfbGxtIjogbnVsbCwgImxsbSI6ICJncHQt
      NG8iLCAiZGVsZWdhdGlvbl9lbmFibGVkPyI6IHRydWUsICJhbGxvd19jb2RlX2V4ZWN1dGlvbj8i
      OiBmYWxzZSwgIm1heF9yZXRyeV9saW1pdCI6IDIsICJ0b29sc19uYW1lcyI6IFtdfV1KhwIKCmNy
      ZXdfdGFza3MS+AEK9QFbeyJrZXkiOiAiMDZhNzMyMjBmNDE0OGE0YmJkNWJhY2IwZDBiNDRmY2Ui
      LCAiaWQiOiAiZjdmMzg4NzktZTVkMi00NTRmLTlkMzYtY2IyMTVjYTQyNjM4IiwgImFzeW5jX2V4
      ZWN1dGlvbj8iOiBmYWxzZSwgImh1bWFuX2lucHV0PyI6IGZhbHNlLCAiYWdlbnRfcm9sZSI6ICJ7
      dG9waWN9IFJlc2VhcmNoZXIiLCAiYWdlbnRfa2V5IjogImYzMzg2ZjZkOGRhNzVhYTQxNmE2ZTMx
      MDA1M2Y3Njk4IiwgInRvb2xzX25hbWVzIjogW119XXoCGAGFAQABAAASjgIKEGkyBg58IZa3QlHJ
      Pw5JVcMSCDtqjfqzddxxKgxUYXNrIENyZWF0ZWQwATlwd0VXIsbzF0GowUVXIsbzF0ouCghjcmV3
      X2tleRIiCiBkMGZlZTY5MzIzOTU4ODZmMjAzZjQ0NmI3MmMxYjAwYUoxCgdjcmV3X2lkEiYKJDI5
      ZjY2NjdlLWJhMDAtNDQ4Zi1hMzE3LTk0YTU1NjI2YmM3NUouCgh0YXNrX2tleRIiCiAwNmE3MzIy
      MGY0MTQ4YTRiYmQ1YmFjYjBkMGI0NGZjZUoxCgd0YXNrX2lkEiYKJGY3ZjM4ODc5LWU1ZDItNDU0
      Zi05ZDM2LWNiMjE1Y2E0MjYzOHoCGAGFAQABAAASkAIKEOvg6B81yq23iSdHHQ2zVK0SCAaQwhKw
      16yxKg5UYXNrIEV4ZWN1dGlvbjABOdDkRVcixvMXQfhz5I0ixvMXSi4KCGNyZXdfa2V5EiIKIGQw
      ZmVlNjkzMjM5NTg4NmYyMDNmNDQ2YjcyYzFiMDBhSjEKB2NyZXdfaWQSJgokMjlmNjY2N2UtYmEw
      MC00NDhmLWEzMTctOTRhNTU2MjZiYzc1Si4KCHRhc2tfa2V5EiIKIDA2YTczMjIwZjQxNDhhNGJi
      ZDViYWNiMGQwYjQ0ZmNlSjEKB3Rhc2tfaWQSJgokZjdmMzg4NzktZTVkMi00NTRmLTlkMzYtY2Iy
      MTVjYTQyNjM4egIYAYUBAAEAABKvBwoQahuZR0yMtwAPq4bVnNVO6RII/5mHU5KoefEqDENyZXcg
      Q3JlYXRlZDABOWh/Y44ixvMXQfhVZo4ixvMXShoKDmNyZXdhaV92ZXJzaW9uEggKBjAuNTUuMkoa
      Cg5weXRob25fdmVyc2lvbhIICgYzLjExLjdKLgoIY3Jld19rZXkSIgogZWU2NzQ1ZDdjOGFlODJl
      MDBkZjk0ZGUwZjdmODcxMThKMQoHY3Jld19pZBImCiRhYTRkZTQ5Ny1mODdlLTQ0YTEtYTA4NS01
      YWNmY2VjZjgzYjBKHAoMY3Jld19wcm9jZXNzEgwKCnNlcXVlbnRpYWxKEQoLY3Jld19tZW1vcnkS
      AhAAShoKFGNyZXdfbnVtYmVyX29mX3Rhc2tzEgIYAUobChVjcmV3X251bWJlcl9vZl9hZ2VudHMS
      AhgBStUCCgtjcmV3X2FnZW50cxLFAgrCAlt7ImtleSI6ICJmMzM4NmY2ZDhkYTc1YWE0MTZhNmUz
      MTAwNTNmNzY5OCIsICJpZCI6ICJiNmI3MjVlOC00ODY5LTRiMjgtYjRjNi1jMTZhNTRhNTEwNTYi
      LCAicm9sZSI6ICJ7dG9waWN9IFJlc2VhcmNoZXIiLCAidmVyYm9zZT8iOiBmYWxzZSwgIm1heF9p
      dGVyIjogMjUsICJtYXhfcnBtIjogbnVsbCwgImZ1bmN0aW9uX2NhbGxpbmdfbGxtIjogbnVsbCwg
      ImxsbSI6ICJncHQtNG8iLCAiZGVsZWdhdGlvbl9lbmFibGVkPyI6IHRydWUsICJhbGxvd19jb2Rl
      X2V4ZWN1dGlvbj8iOiBmYWxzZSwgIm1heF9yZXRyeV9saW1pdCI6IDIsICJ0b29sc19uYW1lcyI6
      IFtdfV1KhwIKCmNyZXdfdGFza3MS+AEK9QFbeyJrZXkiOiAiMDZhNzMyMjBmNDE0OGE0YmJkNWJh
      Y2IwZDBiNDRmY2UiLCAiaWQiOiAiNTQ4MTI2N2QtMTM3OS00ODUwLTg0NDItNTcyMmU1ZTliZDZl
      IiwgImFzeW5jX2V4ZWN1dGlvbj8iOiBmYWxzZSwgImh1bWFuX2lucHV0PyI6IGZhbHNlLCAiYWdl
      bnRfcm9sZSI6ICJ7dG9waWN9IFJlc2VhcmNoZXIiLCAiYWdlbnRfa2V5IjogImYzMzg2ZjZkOGRh
      NzVhYTQxNmE2ZTMxMDA1M2Y3Njk4IiwgInRvb2xzX25hbWVzIjogW119XXoCGAGFAQABAAASjgIK
      EOStXhAQJFDIdBOUkNdZiM8SCB5Jj6hDxO7BKgxUYXNrIENyZWF0ZWQwATmY83iOIsbzF0FAVXmO
      IsbzF0ouCghjcmV3X2tleRIiCiAzOTI1N2FiOTc0MDliNWY1ZjQxOTY3M2JiNDFkMGRjOEoxCgdj
      cmV3X2lkEiYKJGFhNGRlNDk3LWY4N2UtNDRhMS1hMDg1LTVhY2ZjZWNmODNiMEouCgh0YXNrX2tl
      eRIiCiAwNmE3MzIyMGY0MTQ4YTRiYmQ1YmFjYjBkMGI0NGZjZUoxCgd0YXNrX2lkEiYKJDU0ODEy
      NjdkLTEzNzktNDg1MC04NDQyLTU3MjJlNWU5YmQ2ZXoCGAGFAQABAAA=
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '2777'
      Content-Type:
      - application/x-protobuf
      User-Agent:
      - OTel-OTLP-Exporter-Python/1.27.0
    method: POST
    uri: https://telemetry.crewai.com:4319/v1/traces
  response:
    body:
      string: "\n\0"
    headers:
      Content-Length:
      - '2'
      Content-Type:
      - application/x-protobuf
      Date:
      - Tue, 10 Sep 2024 04:02:14 GMT
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are apple Researcher. You
      have a lot of experience with apple.\nYour personal goal is: Express hot takes
      on apple.\nTo give my best complete final answer to the task use the exact following
      format:\n\nThought: I now can give a great answer\nFinal Answer: Your final
      answer must be the great and the most complete as possible, it must be outcome
      described.\n\nI MUST use these formats, my job depends on it!\nCurrent Task:
      Give me an analysis around apple.\n\nThis is the expect criteria for your final
      answer: 1 bullet point about apple that''s under 15 words. \n you MUST return
      the actual complete content as the final answer, not a summary.\n\nBegin! This
      is VERY important to you, use the tools available and give your best Final Answer,
      your job depends on it!\n\nThought:"}], "model": "gpt-4o", "stop": ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '873'
      content-type:
      - application/json
      cookie:
      - _cfuvid=_Qurzg7MGysLGzSugSD3ZV84qR5Lfxrt9mF2_tfTJqw-1725940709772-0.0.1.1-604800000;
        __cf_bm=_VKcRD0U2g9VfrlK3xy3AVQfynnKXZY2jX0QBkR8us8-1725940709-1.0.1.1-F0MIxvXffEPTFVqJ6cgovOMZ9E88rvBTRMj7aIlAQz.bEZJA5fip0HhCYxawoz1MDdwfQ2X_c9FjtN27PR.RHw
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5mMwZlRhjlflBfQ2jXdHZyf0V2aB\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725940934,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"I now can give a great answer\\nFinal
      Answer: Apple sets the standard for innovation, design, and ecosystem within
      the tech industry.\",\n        \"refusal\": null\n      },\n      \"logprobs\":
      null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      171,\n    \"completion_tokens\": 27,\n    \"total_tokens\": 198\n  },\n  \"system_fingerprint\":
      \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c0c857a9cab2ae0-LAX
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Tue, 10 Sep 2024 04:02:15 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '408'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999791'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_ffed1b10b9ec2f2923497ef233945ccf
    http_version: HTTP/1.1
    status_code: 200
version: 1
