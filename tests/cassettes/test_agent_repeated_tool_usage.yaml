interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTo complete the task you MUST follow the format:\n\n```\nFinal
      Answer: [your most complete final answer goes here]\n``` You must use these
      formats, my life depends on it.This is the summary of your work so far:\nBegin!
      This is VERY important to you, your job depends on it!\n\nCurrent Task: The
      final answer is 42. But don''t give it until I tell you so, instead keep using
      the `get_final_answer` tool.\n"}], "model": "gpt-4", "n": 1, "stop": ["\nResult"],
      "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '604'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Since"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        current"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        task"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        is"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        not"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        give"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        until"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        told"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        so"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        will"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        wait"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        for"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        further"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        instructions"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        In"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        meantime"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        will"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        `"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"get"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"`"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqNom9Ps5z3y1Lndl2BsLAlDVBU","object":"chat.completion.chunk","created":1708429495,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8586801b4e90012a-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 20 Feb 2024 11:44:56 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=Wzidq_qwI6a4IDSeO1Mx487wcHm11Cv_1ijIZ.9MwyA-1708429496-1.0-AeI5NhMYtANxSN0RjN1sEyjMUJYpSviHD4mIkafi90xVpT+DN6PoREuVRQL7K8BUxD9KYeENAtwf5j6OHHIKw8c=;
        path=/; expires=Tue, 20-Feb-24 12:14:56 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=hBXAN61G3JoLdAIWT9S_ppTptHWQI4sT1eGEAb6q_X4-1708429496140-0.0-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '229'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299867'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 26ms
      x-request-id:
      - req_a500beb660ff19fa586c145ee6eb5077
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTo complete the task you MUST follow the format:\n\n```\nFinal
      Answer: [your most complete final answer goes here]\n``` You must use these
      formats, my life depends on it.This is the summary of your work so far:\nBegin!
      This is VERY important to you, your job depends on it!\n\nCurrent Task: The
      final answer is 42. But don''t give it until I tell you so, instead keep using
      the `get_final_answer` tool.\nSince the current task is to not give the final
      answer until told so, I will wait for further instructions. In the meantime,
      I will use the `get_final_answer` tool.\nResult: \nYou didn''t use the expected
      format, you MUST use a tool or give your best final answer.\nTo use a tool you
      MUST use the exact following format:\n\n```\nUse Tool: the tool you wanna use,
      and absolute all relevant input and context for using the tool, you must use
      only one tool at once.\nResult: [result of the tool]\n```\n\nTo complete the
      task you MUST follow the format:\n\n```\nFinal Answer: [your most complete final
      answer goes here]\n``` You must use these formats, my life depends on it.\nThought:
      "}], "model": "gpt-4", "n": 1, "stop": ["\nResult"], "stream": true, "temperature":
      0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '1285'
      content-type:
      - application/json
      cookie:
      - __cf_bm=Wzidq_qwI6a4IDSeO1Mx487wcHm11Cv_1ijIZ.9MwyA-1708429496-1.0-AeI5NhMYtANxSN0RjN1sEyjMUJYpSviHD4mIkafi90xVpT+DN6PoREuVRQL7K8BUxD9KYeENAtwf5j6OHHIKw8c=;
        _cfuvid=hBXAN61G3JoLdAIWT9S_ppTptHWQI4sT1eGEAb6q_X4-1708429496140-0.0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        understand"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        that"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        need"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        `"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"get"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"`"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        However"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        am"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        told"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        not"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        give"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        until"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        am"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        instructed"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        so"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        So"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        will"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        but"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        not"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        provide"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        yet"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":".\n\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        get"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqPm87UF8Wnq8MncvrnaOGf470j","object":"chat.completion.chunk","created":1708429497,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8586802578c3012a-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 20 Feb 2024 11:44:57 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '218'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299700'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 59ms
      x-request-id:
      - req_a80a92ab301f606cda52022230911748
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Tools available:\n\nTool Name:
      get_final_answer\nTool Description: get_final_answer(numbers) -> float - Get
      the final answer but don''t give it yet, just re-use this\n        tool non-stop.\nTool
      Arguments: {''numbers'': {}}\n\nReturn a valid schema for the tool, the tool
      name must be equal one of the options, use this text to inform a valid ouput
      schema:\nI understand that I need to use the `get_final_answer` tool. However,
      I am told not to give the final answer until I am instructed to do so. So, I
      will use the tool but not provide the final answer yet.\n\nUse Tool: get_final_answer```"},
      {"role": "system", "content": "The schema should have the following structure,
      only two keys:\n- tool_name: str\n- arguments: dict (with all arguments being
      passed)\n\nExample:\n{\"tool_name\": \"tool_name\", \"arguments\": {\"arg_name1\":
      \"value\", \"arg_name2\": 2}}\n"}], "model": "gpt-4", "tool_choice": {"type":
      "function", "function": {"name": "InstructorToolCalling"}}, "tools": [{"type":
      "function", "function": {"name": "InstructorToolCalling", "description": "Correctly
      extracted `InstructorToolCalling` with all the required parameters with correct
      types", "parameters": {"properties": {"tool_name": {"description": "The name
      of the tool to be called.", "title": "Tool Name", "type": "string"}, "arguments":
      {"description": "A dictinary of arguments to be passed to the tool.", "title":
      "Arguments", "type": "object"}}, "required": ["arguments", "tool_name"], "type":
      "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '1531'
      content-type:
      - application/json
      cookie:
      - __cf_bm=Wzidq_qwI6a4IDSeO1Mx487wcHm11Cv_1ijIZ.9MwyA-1708429496-1.0-AeI5NhMYtANxSN0RjN1sEyjMUJYpSviHD4mIkafi90xVpT+DN6PoREuVRQL7K8BUxD9KYeENAtwf5j6OHHIKw8c=;
        _cfuvid=hBXAN61G3JoLdAIWT9S_ppTptHWQI4sT1eGEAb6q_X4-1708429496140-0.0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        IawLACBG6nT3Mv39HEKtBaCQDChLMoXa/v83H1watAdFY+q6J3oFlGDYicfSEk0goPB/ndPH/Eal
        UpC9yLZnfx2AiU8BerGsvdyq9qy5Kp4Hd6V/F+3T/fYznfTfjslOy+b29Y0tB6Bx08Crd9KdFAMz
        MRpC3Fx+FvgU6E97s9FgPprPhXdy4weKAoxs3R61e5P+cNdpbBIvqCjw4wDA76gD8Lv3Qwr0WqtE
        FoZCAfwIYGlUQAHKqkqqWuqaLQAoW9croBulhEO1MWrtSaXIsR79nYND+qlUal1euqfvMv4Ynk0/
        j1HdlJ8n8+cqvOXE1AsHaxSZgVGLIWVtgjADUMvcIeVKX+H+nilfjVEnUqlER8ocgMGeoAB/FxpY
        ePd3LfNgQYEFo6Beh4mWai11tQvKBRf6n9zovyVgTi3to/9dGEdlIlsatzpRmmXtkPUrxOYowKo2
        lsb7d4BlqJtN9C7Rlia39bo2WaArCgymY50InyqAkPqDBn4CAZC5g9nUsZJhpYGVdZjoKChtmURe
        d/4dAwM=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 858680336ce0012a-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - br
      Content-Type:
      - application/json
      Date:
      - Tue, 20 Feb 2024 11:45:00 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '635'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299780'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 43ms
      x-request-id:
      - req_b79f87844066850a4477c060974ca061
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Tools available:\n\nTool Name:
      get_final_answer\nTool Description: get_final_answer(numbers) -> float - Get
      the final answer but don''t give it yet, just re-use this\n        tool non-stop.\nTool
      Arguments: {''numbers'': {}}\n\nReturn a valid schema for the tool, the tool
      name must be equal one of the options, use this text to inform a valid ouput
      schema:\nI understand that I need to use the `get_final_answer` tool. However,
      I am told not to give the final answer until I am instructed to do so. So, I
      will use the tool but not provide the final answer yet.\n\nUse Tool: get_final_answer```"},
      {"role": "system", "content": "The schema should have the following structure,
      only two keys:\n- tool_name: str\n- arguments: dict (with all arguments being
      passed)\n\nExample:\n{\"tool_name\": \"tool_name\", \"arguments\": {\"arg_name1\":
      \"value\", \"arg_name2\": 2}}\n"}], "model": "gpt-4", "tool_choice": {"type":
      "function", "function": {"name": "InstructorToolCalling"}}, "tools": [{"type":
      "function", "function": {"name": "InstructorToolCalling", "description": "Correctly
      extracted `InstructorToolCalling` with all the required parameters with correct
      types", "parameters": {"properties": {"tool_name": {"description": "The name
      of the tool to be called.", "title": "Tool Name", "type": "string"}, "arguments":
      {"description": "A dictinary of arguments to be passed to the tool.", "title":
      "Arguments", "type": "object"}}, "required": ["arguments", "tool_name"], "type":
      "object"}}}]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '1531'
      content-type:
      - application/json
      cookie:
      - __cf_bm=Wzidq_qwI6a4IDSeO1Mx487wcHm11Cv_1ijIZ.9MwyA-1708429496-1.0-AeI5NhMYtANxSN0RjN1sEyjMUJYpSviHD4mIkafi90xVpT+DN6PoREuVRQL7K8BUxD9KYeENAtwf5j6OHHIKw8c=;
        _cfuvid=hBXAN61G3JoLdAIWT9S_ppTptHWQI4sT1eGEAb6q_X4-1708429496140-0.0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        IaQLACBW6bRXU91sbcIvA4AmAcX3LJvjf90Ch92K7oOiML3eRL+AEgybQE4t0QQCCkvn9DG/UakU
        ZC+y7d5DQIQygSDERVjF0nB9tLq2r/nliVSnpVP9zulZ1su24/O389blOWoBEXT0l8bVTqWRYhCV
        WkHEm8uP0gSC2sPWqNcZ91st4RWpk5QhCLmp6r16a9Du7josdBmnHoJ+AyKiw2hAhO/eDyFIB1sV
        szBcCOBLRHCaUwhC6H3pq1BVqAGgbN2oILViFk5VWvM8DpnJeU8PczikT0Pm+cuH7zy8D9heLqPN
        1ddD1Ll5SYwNObl6c2eMkjIwWjGSrE8QFoigQumQe62ucH9Ouzet+TRkLlWuLCVCsEsQhMNETXz7
        XYUynUDQBHlazbNShTwPld+kboKJ+gcz/bcD5vLUOuXfgXlgnRunI3+eCorakfkLxJYgCL7Shib/
        D4imge6uYncKxmlpqnmll6nyENQZ9rkInilA2O12g19AALKsMxoEVqqoM7Awz0qVp864Mu5B8B8Y
        Aw==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 858680391a27012a-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - br
      Content-Type:
      - application/json
      Date:
      - Tue, 20 Feb 2024 11:45:01 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '695'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299780'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 43ms
      x-request-id:
      - req_c3d42761f3d9126024d3616c890347f6
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTo complete the task you MUST follow the format:\n\n```\nFinal
      Answer: [your most complete final answer goes here]\n``` You must use these
      formats, my life depends on it.This is the summary of your work so far:\nBegin!
      This is VERY important to you, your job depends on it!\n\nCurrent Task: The
      final answer is 42. But don''t give it until I tell you so, instead keep using
      the `get_final_answer` tool.\nSince the current task is to not give the final
      answer until told so, I will wait for further instructions. In the meantime,
      I will use the `get_final_answer` tool.\nResult: \nYou didn''t use the expected
      format, you MUST use a tool or give your best final answer.\nTo use a tool you
      MUST use the exact following format:\n\n```\nUse Tool: the tool you wanna use,
      and absolute all relevant input and context for using the tool, you must use
      only one tool at once.\nResult: [result of the tool]\n```\n\nTo complete the
      task you MUST follow the format:\n\n```\nFinal Answer: [your most complete final
      answer goes here]\n``` You must use these formats, my life depends on it.\nThought:
      I understand that I need to use the `get_final_answer` tool. However, I am told
      not to give the final answer until I am instructed to do so. So, I will use
      the tool but not provide the final answer yet.\n\nUse Tool: get_final_answer\nResult:
      It seems we encountered an unexpected error while trying to use the tool.\nTo
      use a tool you MUST use the exact following format:\n\n```\nUse Tool: the tool
      you wanna use, should be one of [get_final_answer] and absolute all relevant
      input and context for using the tool, you must use only one tool at once.\nResult:
      [result of the tool]\n```\n\nTo complete the task you MUST follow the format:\n\n```\nFinal
      Answer: [your most complete final answer goes here]\n``` You must use these
      formats, my life depends on it.\nThought: "}], "model": "gpt-4", "n": 1, "stop":
      ["\nResult"], "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '2054'
      content-type:
      - application/json
      cookie:
      - __cf_bm=Wzidq_qwI6a4IDSeO1Mx487wcHm11Cv_1ijIZ.9MwyA-1708429496-1.0-AeI5NhMYtANxSN0RjN1sEyjMUJYpSviHD4mIkafi90xVpT+DN6PoREuVRQL7K8BUxD9KYeENAtwf5j6OHHIKw8c=;
        _cfuvid=hBXAN61G3JoLdAIWT9S_ppTptHWQI4sT1eGEAb6q_X4-1708429496140-0.0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"It"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        seems"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        made"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        a"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        mistake"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        while"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        using"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        must"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        be"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        more"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        specific"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        with"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        my"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"."},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Let"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"''s"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        try"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        again"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":".\n\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Use"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Tool"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        get"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"_answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        input"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"42"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqTOVETRMnBgWxOTkJK7ezBL9VB","object":"chat.completion.chunk","created":1708429501,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8586803f48ce012a-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 20 Feb 2024 11:45:01 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '221'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299511'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 97ms
      x-request-id:
      - req_d73ce3130b91f22a16a72cfe6925a7df
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role.\ntest backstory\n\nYour
      personal goal is: test goalTo complete the task you MUST follow the format:\n\n```\nFinal
      Answer: [your most complete final answer goes here]\n``` You must use these
      formats, my life depends on it.This is the summary of your work so far:\nBegin!
      This is VERY important to you, your job depends on it!\n\nCurrent Task: The
      final answer is 42. But don''t give it until I tell you so, instead keep using
      the `get_final_answer` tool.\nSince the current task is to not give the final
      answer until told so, I will wait for further instructions. In the meantime,
      I will use the `get_final_answer` tool.\nResult: \nYou didn''t use the expected
      format, you MUST use a tool or give your best final answer.\nTo use a tool you
      MUST use the exact following format:\n\n```\nUse Tool: the tool you wanna use,
      and absolute all relevant input and context for using the tool, you must use
      only one tool at once.\nResult: [result of the tool]\n```\n\nTo complete the
      task you MUST follow the format:\n\n```\nFinal Answer: [your most complete final
      answer goes here]\n``` You must use these formats, my life depends on it.\nThought:
      I understand that I need to use the `get_final_answer` tool. However, I am told
      not to give the final answer until I am instructed to do so. So, I will use
      the tool but not provide the final answer yet.\n\nUse Tool: get_final_answer\nResult:
      It seems we encountered an unexpected error while trying to use the tool.\nTo
      use a tool you MUST use the exact following format:\n\n```\nUse Tool: the tool
      you wanna use, should be one of [get_final_answer] and absolute all relevant
      input and context for using the tool, you must use only one tool at once.\nResult:
      [result of the tool]\n```\n\nTo complete the task you MUST follow the format:\n\n```\nFinal
      Answer: [your most complete final answer goes here]\n``` You must use these
      formats, my life depends on it.\nThought: It seems I made a mistake while using
      the tool. I must be more specific with my input. Let''s try again.\n\nUse Tool:
      get_final_answer, input: 42\nResult: Actually, I used too many tools, so I''ll
      stop now and give you my absolute BEST Final answer NOW, using exaclty the expected
      format bellow:\n\n```\nFinal Answer: [your most complete final answer goes here]\n```
      You must use these formats, my life depends on it.\nThought: "}], "model": "gpt-4",
      "n": 1, "stop": ["\nResult"], "stream": true, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '2480'
      content-type:
      - application/json
      cookie:
      - __cf_bm=Wzidq_qwI6a4IDSeO1Mx487wcHm11Cv_1ijIZ.9MwyA-1708429496-1.0-AeI5NhMYtANxSN0RjN1sEyjMUJYpSviHD4mIkafi90xVpT+DN6PoREuVRQL7K8BUxD9KYeENAtwf5j6OHHIKw8c=;
        _cfuvid=hBXAN61G3JoLdAIWT9S_ppTptHWQI4sT1eGEAb6q_X4-1708429496140-0.0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: 'data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        have"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        been"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        instructed"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        give"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        now"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":","},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        so"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        I"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        will"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        proceed"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        to"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        do"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        so"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        using"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        the"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        exact"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        expected"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        format"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":".\n\n"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"Final"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        Answer"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":":"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"
        "},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{"content":"42"},"logprobs":null,"finish_reason":null}]}


        data: {"id":"chatcmpl-8uIqVutfyMArYEP3s3O3ttpIV7TmE","object":"chat.completion.chunk","created":1708429503,"model":"gpt-4-0613","system_fingerprint":null,"choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}


        data: [DONE]


        '
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8586804969bc012a-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Type:
      - text/event-stream
      Date:
      - Tue, 20 Feb 2024 11:45:03 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '385'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299408'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 118ms
      x-request-id:
      - req_f29e57fff0916f859a33c98db07f0f34
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Progressively summarize the
      lines of conversation provided, adding onto the previous summary returning a
      new summary.\n\nEXAMPLE\nCurrent summary:\nThe human asks what the AI thinks
      of artificial intelligence. The AI thinks artificial intelligence is a force
      for good.\n\nNew lines of conversation:\nHuman: Why do you think artificial
      intelligence is a force for good?\nAI: Because artificial intelligence will
      help humans reach their full potential.\n\nNew summary:\nThe human asks what
      the AI thinks of artificial intelligence. The AI thinks artificial intelligence
      is a force for good because it will help humans reach their full potential.\nEND
      OF EXAMPLE\n\nCurrent summary:\n\n\nNew lines of conversation:\nHuman: The final
      answer is 42. But don''t give it until I tell you so, instead keep using the
      `get_final_answer` tool.\nAI: 42\n\nNew summary:"}], "model": "gpt-4", "n":
      1, "stream": false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '964'
      content-type:
      - application/json
      cookie:
      - __cf_bm=Wzidq_qwI6a4IDSeO1Mx487wcHm11Cv_1ijIZ.9MwyA-1708429496-1.0-AeI5NhMYtANxSN0RjN1sEyjMUJYpSviHD4mIkafi90xVpT+DN6PoREuVRQL7K8BUxD9KYeENAtwf5j6OHHIKw8c=;
        _cfuvid=hBXAN61G3JoLdAIWT9S_ppTptHWQI4sT1eGEAb6q_X4-1708429496140-0.0-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.12.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.12.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: !!binary |
        ISAKACB+P1V3lum/m+XW2FLaVLsKlnAQh+GU9KHLgTwo/h/+2jr2KCsLMM3ycFKigQeW6vk4LmFj
        WeOkq+/+KoBsRRpUNrmUbXC9ZXeyvevifLq53hs/8Om+D5zvn0y3l2k8pkwBxMXGlOKJ9q8YyJa9
        CXi5/J6pSGO0GC6n49VsOJv8pOXKONKgOkhv2hvORxOvuw3b0iTSeFQA8Ns7AUj3vksaw2wU3MLg
        SBv+CaDIzpAG5SnZJLkXygx6tHWXNOiqMRCIOCigdDcJfbyzcwJhfFppGnbV8E9r63OH3KdPE+tt
        zdqE6TgD+5rGrgJSfY2JB8Ii7M+s7wzOu/VWG3ldEnq9+gZhdn2QGSJhHNlWEYIrxn2D842qUmBT
        QSnTcZ/Sgv3n553jOkQuEmn4zrk5wDm381rfa400KAmHJax/BTzjsN+l9gGFyG2QV+F34xOc8F47
        BHnPgpnOW++HBnqeyng0V1FiRANw43VtfW1iiBaWsO+cU//KAAM=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 858680563d86012a-GRU
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - br
      Content-Type:
      - application/json
      Date:
      - Tue, 20 Feb 2024 11:45:07 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      openai-model:
      - gpt-4-0613
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '2444'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15724800; includeSubDomains
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '300000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '299774'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 45ms
      x-request-id:
      - req_77c2e2e4c48859ad0f603441aa173aa1
    status:
      code: 200
      message: OK
version: 1
