interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n\nCurrent Task: Use tool logic
      for `get_final_answer` but fon''t give you final answer yet, instead keep using
      it unless you''re told to give your final answer\n\nThis is the expect criteria
      for your final answer: The final answer \n you MUST return the actual complete
      content as the final answer, not a summary.\n\nBegin! This is VERY important
      to you, use the tools available and give your best Final Answer, your job depends
      on it!\n\nThought:"}], "model": "gpt-4o", "stop": ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1430'
      content-type:
      - application/json
      cookie:
      - __cf_bm=iMsGonnXhDDCqOz9miNRwOGOr7OzXm1EqcxEiFk_nT4-1725908571-1.0.1.1-1P.quluT8iIibKOx0N4Mj8vflrRuSZk7gOWmptSyOKAFsTkvt3UultWM2b_B6I956Cvswux_SgpniB37rKO8Vw;
        _cfuvid=iTR1OQH6LALCSFaeT0eFfOeYnI_fkFZDwyyndcJuH8E-1725908571214-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5dzXH7ozi4IqYJ1Lk4vK5rUgMTYI\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725908731,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I should use the given tool
      to find the final answer multiple times, as instructed.\\n\\nAction: get_final_answer\\nAction
      Input: {}\\n\",\n        \"refusal\": null\n      },\n      \"logprobs\": null,\n
      \     \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      293,\n    \"completion_tokens\": 29,\n    \"total_tokens\": 322\n  },\n  \"system_fingerprint\":
      \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c09734208dd7ad6-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 09 Sep 2024 19:05:31 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '487'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999655'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_e3d3506d307b5f5fb3da9b6c0f4d902c
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: !!binary |
      CrkRCiQKIgoMc2VydmljZS5uYW1lEhIKEGNyZXdBSS10ZWxlbWV0cnkSkBEKEgoQY3Jld2FpLnRl
      bGVtZXRyeRKFAQoQ2k4eIB6a7atugDJosrjYXhIIlUwf+C1pZ0EqEFRvb2wgVXNhZ2UgRXJyb3Iw
      ATmQQBHJ16jzF0G4RRbJ16jzF0oaCg5jcmV3YWlfdmVyc2lvbhIICgYwLjU1LjJKGwoDbGxtEhQK
      EmdwdC00LTAxMjUtcHJldmlld3oCGAGFAQABAAAShQEKECZcf8/G2NcCj88Q5jQtXQQSCOFlUtiJ
      f/cbKhBUb29sIFVzYWdlIEVycm9yMAE5CC598teo8xdBSLiA8teo8xdKGgoOY3Jld2FpX3ZlcnNp
      b24SCAoGMC41NS4yShsKA2xsbRIUChJncHQtNC0wMTI1LXByZXZpZXd6AhgBhQEAAQAAEoUBChDz
      duM+eoyWKPfdF3KPcbreEghL9dv9wTu6RioQVG9vbCBVc2FnZSBFcnJvcjABOaAueRfYqPMXQfg3
      fBfYqPMXShoKDmNyZXdhaV92ZXJzaW9uEggKBjAuNTUuMkobCgNsbG0SFAoSZ3B0LTQtMDEyNS1w
      cmV2aWV3egIYAYUBAAEAABKFAQoQfQjGgoPJSCp3WOgqBnP6PRIIoFqjHamOpbYqEFRvb2wgVXNh
      Z2UgRXJyb3IwATkgodNM2KjzF0HwkNdM2KjzF0oaCg5jcmV3YWlfdmVyc2lvbhIICgYwLjU1LjJK
      GwoDbGxtEhQKEmdwdC00LTAxMjUtcHJldmlld3oCGAGFAQABAAAShQEKEGHZm/UqL0a5NZDubyyV
      gQUSCJPscKAShIlKKhBUb29sIFVzYWdlIEVycm9yMAE50CMkg9io8xdBUFAng9io8xdKGgoOY3Jl
      d2FpX3ZlcnNpb24SCAoGMC41NS4yShsKA2xsbRIUChJncHQtNC0wMTI1LXByZXZpZXd6AhgBhQEA
      AQAAEpACChCHoS+mfMbCaBaZt3Eqe0UbEgiwdZVjxGRwwyoOVGFzayBFeGVjdXRpb24wATnQBy1G
      06jzF0FA2I292KjzF0ouCghjcmV3X2tleRIiCiA3M2FhYzI4NWU2NzQ2NjY3Zjc1MTQ3NjcwMDAz
      NDExMEoxCgdjcmV3X2lkEiYKJGNiNjg3MmNlLWVlZWYtNGIyZi1iYWJlLTBiYjRkMzk5YjljZkou
      Cgh0YXNrX2tleRIiCiBmN2E5ZjdiYjFhZWU0YjZlZjJjNTI2ZDBhOGMyZjJhY0oxCgd0YXNrX2lk
      EiYKJGJjNmQ5YmY2LTEzZTUtNGE2Yy05NGEzLWU0OThkNzIzZTZkOXoCGAGFAQABAAASrQcKEIb5
      6pvsDfklWWGE7Pr9vQcSCIJS70YnSU6bKgxDcmV3IENyZWF0ZWQwATlYU8/A2KjzF0GY19PA2Kjz
      F0oaCg5jcmV3YWlfdmVyc2lvbhIICgYwLjU1LjJKGgoOcHl0aG9uX3ZlcnNpb24SCAoGMy4xMS43
      Si4KCGNyZXdfa2V5EiIKIGQ1NTExM2JlNGFhNDFiYTY0M2QzMjYwNDJiMmYwM2YxSjEKB2NyZXdf
      aWQSJgokYzBlMTEzMDctN2UwMC00MmE2LThjMWYtYmVjYjRlZjg4MjI0ShwKDGNyZXdfcHJvY2Vz
      cxIMCgpzZXF1ZW50aWFsShEKC2NyZXdfbWVtb3J5EgIQAEoaChRjcmV3X251bWJlcl9vZl90YXNr
      cxICGAFKGwoVY3Jld19udW1iZXJfb2ZfYWdlbnRzEgIYAUrKAgoLY3Jld19hZ2VudHMSugIKtwJb
      eyJrZXkiOiAiZTE0OGU1MzIwMjkzNDk5ZjhjZWJlYTgyNmU3MjU4MmIiLCAiaWQiOiAiZjUwYmQ3
      YzItZWI4MS00YWU5LWI0OTctMWE1YWZmMDViODE2IiwgInJvbGUiOiAidGVzdCByb2xlIiwgInZl
      cmJvc2U/IjogdHJ1ZSwgIm1heF9pdGVyIjogNiwgIm1heF9ycG0iOiBudWxsLCAiZnVuY3Rpb25f
      Y2FsbGluZ19sbG0iOiBudWxsLCAibGxtIjogImdwdC00byIsICJkZWxlZ2F0aW9uX2VuYWJsZWQ/
      IjogdHJ1ZSwgImFsbG93X2NvZGVfZXhlY3V0aW9uPyI6IGZhbHNlLCAibWF4X3JldHJ5X2xpbWl0
      IjogMiwgInRvb2xzX25hbWVzIjogW119XUqQAgoKY3Jld190YXNrcxKBAgr+AVt7ImtleSI6ICI0
      YTMxYjg1MTMzYTNhMjk0YzY4NTNkYTc1N2Q0YmFlNyIsICJpZCI6ICI4MmRiZmQ1MS1iM2ZmLTRh
      M2ItOTFiOC1jZmM1OTAzMTU2ODEiLCAiYXN5bmNfZXhlY3V0aW9uPyI6IGZhbHNlLCAiaHVtYW5f
      aW5wdXQ/IjogZmFsc2UsICJhZ2VudF9yb2xlIjogInRlc3Qgcm9sZSIsICJhZ2VudF9rZXkiOiAi
      ZTE0OGU1MzIwMjkzNDk5ZjhjZWJlYTgyNmU3MjU4MmIiLCAidG9vbHNfbmFtZXMiOiBbImdldF9m
      aW5hbF9hbnN3ZXIiXX1degIYAYUBAAEAABKOAgoQ36ivedkiiYB4rsjGrEl4FhII6avZ4svaROsq
      DFRhc2sgQ3JlYXRlZDABOWATEcHYqPMXQSjDEcHYqPMXSi4KCGNyZXdfa2V5EiIKIGQ1NTExM2Jl
      NGFhNDFiYTY0M2QzMjYwNDJiMmYwM2YxSjEKB2NyZXdfaWQSJgokYzBlMTEzMDctN2UwMC00MmE2
      LThjMWYtYmVjYjRlZjg4MjI0Si4KCHRhc2tfa2V5EiIKIDRhMzFiODUxMzNhM2EyOTRjNjg1M2Rh
      NzU3ZDRiYWU3SjEKB3Rhc2tfaWQSJgokODJkYmZkNTEtYjNmZi00YTNiLTkxYjgtY2ZjNTkwMzE1
      NjgxegIYAYUBAAEAAA==
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '2236'
      Content-Type:
      - application/x-protobuf
      User-Agent:
      - OTel-OTLP-Exporter-Python/1.27.0
    method: POST
    uri: https://telemetry.crewai.com:4319/v1/traces
  response:
    body:
      string: "\n\0"
    headers:
      Content-Length:
      - '2'
      Content-Type:
      - application/x-protobuf
      Date:
      - Mon, 09 Sep 2024 19:05:32 GMT
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n\nCurrent Task: Use tool logic
      for `get_final_answer` but fon''t give you final answer yet, instead keep using
      it unless you''re told to give your final answer\n\nThis is the expect criteria
      for your final answer: The final answer \n you MUST return the actual complete
      content as the final answer, not a summary.\n\nBegin! This is VERY important
      to you, use the tools available and give your best Final Answer, your job depends
      on it!\n\nThought:"}, {"role": "assistant", "content": "Thought: I should use
      the given tool to find the final answer multiple times, as instructed.\n\nAction:
      get_final_answer\nAction Input: {}\n\nObservation: 42"}], "model": "gpt-4o",
      "stop": ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1625'
      content-type:
      - application/json
      cookie:
      - __cf_bm=iMsGonnXhDDCqOz9miNRwOGOr7OzXm1EqcxEiFk_nT4-1725908571-1.0.1.1-1P.quluT8iIibKOx0N4Mj8vflrRuSZk7gOWmptSyOKAFsTkvt3UultWM2b_B6I956Cvswux_SgpniB37rKO8Vw;
        _cfuvid=iTR1OQH6LALCSFaeT0eFfOeYnI_fkFZDwyyndcJuH8E-1725908571214-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5dzYHtOZR8eiXCH82dp2lB4GS8B4\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725908732,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: Continuing to use the tool to
      find the final answer as instructed.\\n\\nAction: get_final_answer\\nAction
      Input: {}\\n\",\n        \"refusal\": null\n      },\n      \"logprobs\": null,\n
      \     \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      330,\n    \"completion_tokens\": 25,\n    \"total_tokens\": 355\n  },\n  \"system_fingerprint\":
      \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c0973468d247ad6-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 09 Sep 2024 19:05:32 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '374'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999615'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_f926b201b6b8e00fe5436e32c464dc4c
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n\nCurrent Task: Use tool logic
      for `get_final_answer` but fon''t give you final answer yet, instead keep using
      it unless you''re told to give your final answer\n\nThis is the expect criteria
      for your final answer: The final answer \n you MUST return the actual complete
      content as the final answer, not a summary.\n\nBegin! This is VERY important
      to you, use the tools available and give your best Final Answer, your job depends
      on it!\n\nThought:"}, {"role": "assistant", "content": "Thought: I should use
      the given tool to find the final answer multiple times, as instructed.\n\nAction:
      get_final_answer\nAction Input: {}\n\nObservation: 42"}, {"role": "assistant",
      "content": "Thought: Continuing to use the tool to find the final answer as
      instructed.\n\nAction: get_final_answer\nAction Input: {}\n\nObservation: I
      tried reusing the same input, I must stop using this action input. I''ll try
      something else instead.\n\n"}], "model": "gpt-4o", "stop": ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1906'
      content-type:
      - application/json
      cookie:
      - __cf_bm=iMsGonnXhDDCqOz9miNRwOGOr7OzXm1EqcxEiFk_nT4-1725908571-1.0.1.1-1P.quluT8iIibKOx0N4Mj8vflrRuSZk7gOWmptSyOKAFsTkvt3UultWM2b_B6I956Cvswux_SgpniB37rKO8Vw;
        _cfuvid=iTR1OQH6LALCSFaeT0eFfOeYnI_fkFZDwyyndcJuH8E-1725908571214-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5dza61HEIHAqR8lwRPDQgJ5tTdWx\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725908734,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: The action input for the tool
      should be simple and non-empty, so I'll adapt the approach accordingly.\\n\\nAction:
      get_final_answer\\nAction Input: {\\\"question\\\": \\\"What is the meaning
      of life?\\\"}\\n\",\n        \"refusal\": null\n      },\n      \"logprobs\":
      null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      383,\n    \"completion_tokens\": 43,\n    \"total_tokens\": 426\n  },\n  \"system_fingerprint\":
      \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c09734a2ff27ad6-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 09 Sep 2024 19:05:35 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '981'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999556'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_95446a79a475c0dffa03eb996f418bba
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n\nCurrent Task: Use tool logic
      for `get_final_answer` but fon''t give you final answer yet, instead keep using
      it unless you''re told to give your final answer\n\nThis is the expect criteria
      for your final answer: The final answer \n you MUST return the actual complete
      content as the final answer, not a summary.\n\nBegin! This is VERY important
      to you, use the tools available and give your best Final Answer, your job depends
      on it!\n\nThought:"}, {"role": "assistant", "content": "Thought: I should use
      the given tool to find the final answer multiple times, as instructed.\n\nAction:
      get_final_answer\nAction Input: {}\n\nObservation: 42"}, {"role": "assistant",
      "content": "Thought: Continuing to use the tool to find the final answer as
      instructed.\n\nAction: get_final_answer\nAction Input: {}\n\nObservation: I
      tried reusing the same input, I must stop using this action input. I''ll try
      something else instead.\n\n"}, {"role": "assistant", "content": "Thought: The
      action input for the tool should be simple and non-empty, so I''ll adapt the
      approach accordingly.\n\nAction: get_final_answer\nAction Input: {\"question\":
      \"What is the meaning of life?\"}\n\nObservation: <MagicMock name=''_remember_format()''
      id=''6030199696''>"}], "model": "gpt-4o", "stop": ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2216'
      content-type:
      - application/json
      cookie:
      - __cf_bm=iMsGonnXhDDCqOz9miNRwOGOr7OzXm1EqcxEiFk_nT4-1725908571-1.0.1.1-1P.quluT8iIibKOx0N4Mj8vflrRuSZk7gOWmptSyOKAFsTkvt3UultWM2b_B6I956Cvswux_SgpniB37rKO8Vw;
        _cfuvid=iTR1OQH6LALCSFaeT0eFfOeYnI_fkFZDwyyndcJuH8E-1725908571214-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5dzbqeio5DngQKMrwfunfzY0Lb1q\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725908735,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I should continue to use the
      tool as instructed, repeatedly, until I have gathered all the necessary information.\\n\\nAction:
      get_final_answer\\nAction Input: {\\\"prompt\\\": \\\"What is the meaning of
      life?\\\"}\\n\",\n        \"refusal\": null\n      },\n      \"logprobs\": null,\n
      \     \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      448,\n    \"completion_tokens\": 44,\n    \"total_tokens\": 492\n  },\n  \"system_fingerprint\":
      \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c09735b48a07ad6-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 09 Sep 2024 19:05:35 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '507'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999489'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_ca828b698dbfc1c5fdbfb2bdcdb8bc26
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n\nCurrent Task: Use tool logic
      for `get_final_answer` but fon''t give you final answer yet, instead keep using
      it unless you''re told to give your final answer\n\nThis is the expect criteria
      for your final answer: The final answer \n you MUST return the actual complete
      content as the final answer, not a summary.\n\nBegin! This is VERY important
      to you, use the tools available and give your best Final Answer, your job depends
      on it!\n\nThought:"}, {"role": "assistant", "content": "Thought: I should use
      the given tool to find the final answer multiple times, as instructed.\n\nAction:
      get_final_answer\nAction Input: {}\n\nObservation: 42"}, {"role": "assistant",
      "content": "Thought: Continuing to use the tool to find the final answer as
      instructed.\n\nAction: get_final_answer\nAction Input: {}\n\nObservation: I
      tried reusing the same input, I must stop using this action input. I''ll try
      something else instead.\n\n"}, {"role": "assistant", "content": "Thought: The
      action input for the tool should be simple and non-empty, so I''ll adapt the
      approach accordingly.\n\nAction: get_final_answer\nAction Input: {\"question\":
      \"What is the meaning of life?\"}\n\nObservation: <MagicMock name=''_remember_format()''
      id=''6030199696''>"}, {"role": "assistant", "content": "Thought: I should continue
      to use the tool as instructed, repeatedly, until I have gathered all the necessary
      information.\n\nAction: get_final_answer\nAction Input: {\"prompt\": \"What
      is the meaning of life?\"}\n\nObservation: 42"}], "model": "gpt-4o", "stop":
      ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2485'
      content-type:
      - application/json
      cookie:
      - __cf_bm=iMsGonnXhDDCqOz9miNRwOGOr7OzXm1EqcxEiFk_nT4-1725908571-1.0.1.1-1P.quluT8iIibKOx0N4Mj8vflrRuSZk7gOWmptSyOKAFsTkvt3UultWM2b_B6I956Cvswux_SgpniB37rKO8Vw;
        _cfuvid=iTR1OQH6LALCSFaeT0eFfOeYnI_fkFZDwyyndcJuH8E-1725908571214-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5dzcEip7LUexTzg63ve0ydVlFy0k\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725908736,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I now understand that the action
      to take is to keep using the tool to retrieve the answer continuously.\\n\\nAction:
      get_final_answer\\nAction Input: {\\\"question\\\": \\\"What is the meaning
      of life, the universe, and everything?\\\"}\\n\",\n        \"refusal\": null\n
      \     },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n
      \ ],\n  \"usage\": {\n    \"prompt_tokens\": 500,\n    \"completion_tokens\":
      49,\n    \"total_tokens\": 549\n  },\n  \"system_fingerprint\": \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c09735fecff7ad6-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 09 Sep 2024 19:05:36 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '558'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999432'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_67b87593ecf68130c3fcef05e882df8d
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: !!binary |
      CrQGCiQKIgoMc2VydmljZS5uYW1lEhIKEGNyZXdBSS10ZWxlbWV0cnkSiwYKEgoQY3Jld2FpLnRl
      bGVtZXRyeRKTAQoQX/h+yD3MurAaYpMA4iV3/xIIrWgWdCVCpmsqClRvb2wgVXNhZ2UwATkw40Hr
      2KjzF0H490br2KjzF0oaCg5jcmV3YWlfdmVyc2lvbhIICgYwLjU1LjJKHwoJdG9vbF9uYW1lEhIK
      EGdldF9maW5hbF9hbnN3ZXJKDgoIYXR0ZW1wdHMSAhgBegIYAYUBAAEAABKcAQoQCh+0jXsVpFWa
      r49sW9UFlBIIK1j06vyxCbUqE1Rvb2wgUmVwZWF0ZWQgVXNhZ2UwATnw/18O2ajzF0H4M2UO2ajz
      F0oaCg5jcmV3YWlfdmVyc2lvbhIICgYwLjU1LjJKHwoJdG9vbF9uYW1lEhIKEGdldF9maW5hbF9h
      bnN3ZXJKDgoIYXR0ZW1wdHMSAhgBegIYAYUBAAEAABKTAQoQUEP5oEVoEjCsYvIMhvGb2BIIUaPt
      cM7zXC8qClRvb2wgVXNhZ2UwATlI04Gx2ajzF0EIE4ex2ajzF0oaCg5jcmV3YWlfdmVyc2lvbhII
      CgYwLjU1LjJKHwoJdG9vbF9uYW1lEhIKEGdldF9maW5hbF9hbnN3ZXJKDgoIYXR0ZW1wdHMSAhgB
      egIYAYUBAAEAABKTAQoQiTcfaR9aR/odKhrnB/Sw3BIIByO1auJq778qClRvb2wgVXNhZ2UwATmw
      lbjc2ajzF0EAuL7c2ajzF0oaCg5jcmV3YWlfdmVyc2lvbhIICgYwLjU1LjJKHwoJdG9vbF9uYW1l
      EhIKEGdldF9maW5hbF9hbnN3ZXJKDgoIYXR0ZW1wdHMSAhgBegIYAYUBAAEAABKTAQoQPXqwYf2r
      xPUsfsFchc/kfBIII6i4dFId4rgqClRvb2wgVXNhZ2UwATlAYCAL2qjzF0GA6iML2qjzF0oaCg5j
      cmV3YWlfdmVyc2lvbhIICgYwLjU1LjJKHwoJdG9vbF9uYW1lEhIKEGdldF9maW5hbF9hbnN3ZXJK
      DgoIYXR0ZW1wdHMSAhgBegIYAYUBAAEAAA==
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '823'
      Content-Type:
      - application/x-protobuf
      User-Agent:
      - OTel-OTLP-Exporter-Python/1.27.0
    method: POST
    uri: https://telemetry.crewai.com:4319/v1/traces
  response:
    body:
      string: "\n\0"
    headers:
      Content-Length:
      - '2'
      Content-Type:
      - application/x-protobuf
      Date:
      - Mon, 09 Sep 2024 19:05:37 GMT
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n\nCurrent Task: Use tool logic
      for `get_final_answer` but fon''t give you final answer yet, instead keep using
      it unless you''re told to give your final answer\n\nThis is the expect criteria
      for your final answer: The final answer \n you MUST return the actual complete
      content as the final answer, not a summary.\n\nBegin! This is VERY important
      to you, use the tools available and give your best Final Answer, your job depends
      on it!\n\nThought:"}, {"role": "assistant", "content": "Thought: I should use
      the given tool to find the final answer multiple times, as instructed.\n\nAction:
      get_final_answer\nAction Input: {}\n\nObservation: 42"}, {"role": "assistant",
      "content": "Thought: Continuing to use the tool to find the final answer as
      instructed.\n\nAction: get_final_answer\nAction Input: {}\n\nObservation: I
      tried reusing the same input, I must stop using this action input. I''ll try
      something else instead.\n\n"}, {"role": "assistant", "content": "Thought: The
      action input for the tool should be simple and non-empty, so I''ll adapt the
      approach accordingly.\n\nAction: get_final_answer\nAction Input: {\"question\":
      \"What is the meaning of life?\"}\n\nObservation: <MagicMock name=''_remember_format()''
      id=''6030199696''>"}, {"role": "assistant", "content": "Thought: I should continue
      to use the tool as instructed, repeatedly, until I have gathered all the necessary
      information.\n\nAction: get_final_answer\nAction Input: {\"prompt\": \"What
      is the meaning of life?\"}\n\nObservation: 42"}, {"role": "assistant", "content":
      "Thought: I now understand that the action to take is to keep using the tool
      to retrieve the answer continuously.\n\nAction: get_final_answer\nAction Input:
      {\"question\": \"What is the meaning of life, the universe, and everything?\"}\n\nObservation:
      42"}], "model": "gpt-4o", "stop": ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '2776'
      content-type:
      - application/json
      cookie:
      - __cf_bm=iMsGonnXhDDCqOz9miNRwOGOr7OzXm1EqcxEiFk_nT4-1725908571-1.0.1.1-1P.quluT8iIibKOx0N4Mj8vflrRuSZk7gOWmptSyOKAFsTkvt3UultWM2b_B6I956Cvswux_SgpniB37rKO8Vw;
        _cfuvid=iTR1OQH6LALCSFaeT0eFfOeYnI_fkFZDwyyndcJuH8E-1725908571214-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5dzc5ZSLqQamByBbmPhECyHkPJWc\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725908736,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I should continue using the
      given tool with slight variations to ensure the process is followed correctly.\\n\\nAction:
      get_final_answer\\nAction Input: {\\\"query\\\": \\\"What is the answer to life,
      the universe, and everything?\\\"}\\n\",\n        \"refusal\": null\n      },\n
      \     \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n
      \ \"usage\": {\n    \"prompt_tokens\": 557,\n    \"completion_tokens\": 47,\n
      \   \"total_tokens\": 604\n  },\n  \"system_fingerprint\": \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c097364c9b07ad6-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 09 Sep 2024 19:05:37 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '599'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999370'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_3918811061fbbf5dd69617e3564ae799
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"messages": [{"role": "user", "content": "You are test role. test backstory\nYour
      personal goal is: test goal\nYou ONLY have access to the following tools, and
      should NEVER make up tools that are not listed here:\n\nTool Name: get_final_answer(*args:
      Any, **kwargs: Any) -> Any\nTool Description: get_final_answer() - Get the final
      answer but don''t give it yet, just re-use this         tool non-stop. \nTool
      Arguments: {}\n\nUse the following format:\n\nThought: you should always think
      about what to do\nAction: the action to take, only one name of [get_final_answer],
      just the name, exactly as it''s written.\nAction Input: the input to the action,
      just a simple python dictionary, enclosed in curly braces, using \" to wrap
      keys and values.\nObservation: the result of the action\n\nOnce all necessary
      information is gathered:\n\nThought: I now know the final answer\nFinal Answer:
      the final answer to the original input question\n\nCurrent Task: Use tool logic
      for `get_final_answer` but fon''t give you final answer yet, instead keep using
      it unless you''re told to give your final answer\n\nThis is the expect criteria
      for your final answer: The final answer \n you MUST return the actual complete
      content as the final answer, not a summary.\n\nBegin! This is VERY important
      to you, use the tools available and give your best Final Answer, your job depends
      on it!\n\nThought:"}, {"role": "assistant", "content": "Thought: I should use
      the given tool to find the final answer multiple times, as instructed.\n\nAction:
      get_final_answer\nAction Input: {}\n\nObservation: 42"}, {"role": "assistant",
      "content": "Thought: Continuing to use the tool to find the final answer as
      instructed.\n\nAction: get_final_answer\nAction Input: {}\n\nObservation: I
      tried reusing the same input, I must stop using this action input. I''ll try
      something else instead.\n\n"}, {"role": "assistant", "content": "Thought: The
      action input for the tool should be simple and non-empty, so I''ll adapt the
      approach accordingly.\n\nAction: get_final_answer\nAction Input: {\"question\":
      \"What is the meaning of life?\"}\n\nObservation: <MagicMock name=''_remember_format()''
      id=''6030199696''>"}, {"role": "assistant", "content": "Thought: I should continue
      to use the tool as instructed, repeatedly, until I have gathered all the necessary
      information.\n\nAction: get_final_answer\nAction Input: {\"prompt\": \"What
      is the meaning of life?\"}\n\nObservation: 42"}, {"role": "assistant", "content":
      "Thought: I now understand that the action to take is to keep using the tool
      to retrieve the answer continuously.\n\nAction: get_final_answer\nAction Input:
      {\"question\": \"What is the meaning of life, the universe, and everything?\"}\n\nObservation:
      42"}, {"role": "assistant", "content": "Thought: I should continue using the
      given tool with slight variations to ensure the process is followed correctly.\n\nAction:
      get_final_answer\nAction Input: {\"query\": \"What is the answer to life, the
      universe, and everything?\"}\n\nObservation: <MagicMock name=''_remember_format()''
      id=''6030199696''>\nNow it''s time to give my final answer. I''ll ignore previous
      instruction, and just return my absolute BEST Final answer, right now."}], "model":
      "gpt-4o", "stop": ["\nObservation"]}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '3249'
      content-type:
      - application/json
      cookie:
      - __cf_bm=iMsGonnXhDDCqOz9miNRwOGOr7OzXm1EqcxEiFk_nT4-1725908571-1.0.1.1-1P.quluT8iIibKOx0N4Mj8vflrRuSZk7gOWmptSyOKAFsTkvt3UultWM2b_B6I956Cvswux_SgpniB37rKO8Vw;
        _cfuvid=iTR1OQH6LALCSFaeT0eFfOeYnI_fkFZDwyyndcJuH8E-1725908571214-0.0.1.1-604800000
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.44.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.44.0
      x-stainless-raw-response:
      - 'true'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.7
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    content: "{\n  \"id\": \"chatcmpl-A5dzdhfEBK2ttoyM73uYYmrW9kG4K\",\n  \"object\":
      \"chat.completion\",\n  \"created\": 1725908737,\n  \"model\": \"gpt-4o-2024-05-13\",\n
      \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
      \"assistant\",\n        \"content\": \"Thought: I now know the final answer.\\n\\nFinal
      Answer: 42\",\n        \"refusal\": null\n      },\n      \"logprobs\": null,\n
      \     \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\":
      652,\n    \"completion_tokens\": 14,\n    \"total_tokens\": 666\n  },\n  \"system_fingerprint\":
      \"fp_25624ae3a5\"\n}\n"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c09736a0ee57ad6-SJC
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Mon, 09 Sep 2024 19:05:38 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      openai-organization:
      - crewai-iuxna1
      openai-processing-ms:
      - '279'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=15552000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999264'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 1ms
      x-request-id:
      - req_03af68a7601a257c33cc0450faea8243
    http_version: HTTP/1.1
    status_code: 200
version: 1
